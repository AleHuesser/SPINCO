rm(list=ls())
library(dplyr)
library(tidyr)
###############################################################################
# SPREADSHEETS TO USE IN GORILLA
# ----------------------------------------------------------------------------
# - Read subsets of items generated by MATCH
# - Assign balanced SNR levels
# - Control pseudowords and their ref words are not in same block (LD task)
# - Export XLS file formmatted for Gorilla(indicating block etc)
###############################################################################


# directories 
dirinput <- 'V:/spinco_data/LIRI_database/SINON_MATCH_subsets_50words'
dirinput100 <- 'V:/spinco_data/LIRI_database/SINON_MATCH_subsets_100words'
databasedfile <-'V:/spinco_data/LIRI_database/LIRI_database_stimuli.xlsx'
diroutput <- 'V:/spinco_data/SINON/Spreadsheets'
setwd(dirinput)
#audiofiles
audiofiles_nvoc <- 'V:/spinco_data/Audio_recordings/LIRI_voice_DF/segments/items_OK_norm_vocoded/'
audiofiles_sissn <- 'V:/spinco_data/Audio_recordings/LIRI_voice_DF/segments/items_OK_norm_SiSSN/'
# 
filesnvoc <- dir(audiofiles_nvoc,pattern = '*.mp3')
filessissn <- dir(audiofiles_sissn,pattern = '*.mp3')

# search files and concat
database <- openxlsx::read.xlsx(databasedfile,sheet = 'Merged')
# SNR assignments to file suffices
snrLev <-   c('snr1','snr2','snr3','snr4','snr5')
snrs_voco <- c('4chans','5chans','6chans','7chans','8chans')
snrs_sissn <- c('10db','5db','0db','-5db','-10db')
 
# SPREADSHEETS  ###################################################################
# Lexical Decision ------------------------------------------

words <- list()
for (i in 1:5){
  currSet <-read.table(paste0('list2match_set',i,'.txt'))
  if (nrow(currSet) %% length(snrLev)!=0){
    stop("not possible to balance n trials per snr ! ")
  }
  #find matching pseudowords  # shuffle and add snr 
  wordsInSet <-database$CORRECT_SPELL[which(database$CORRECT_SPELL %in% currSet$V1)]
  wordsInSet <- wordsInSet %>% sample 
  snrInSet <- rep(snrLev,length(wordsInSet)/5)
  words[[i]] <-as.data.frame(cbind(rep(paste0('block',i),length(wordsInSet)),
                                   wordsInSet,
                                   snrInSet))
}
words <- data.table::rbindlist(words)
colnames(words) <- c('block','item','snr')
#
pseudo <- list()
for (i in 1:5){
  currSet <-read.table(paste0('list2match_set',i,'.txt'))
  if (nrow(currSet) %% length(snrLev)!=0){
    stop("not possible to balance n trials per snr ! ")
  }
  #find matching pseudowords  # shuffle and add snr 
  pseudoInSet <-database$Pseudoword[which(database$CORRECT_SPELL %in% currSet$V1)]
  pseudoInSet <- pseudoInSet %>% gsub('-','',.) %>% sample
  snrInSet <- rep(snrLev,length(pseudoInSet)/5)
  pseudo[[i]] <-as.data.frame(cbind(rep(paste0('block',i),length(pseudoInSet)),
                                    pseudoInSet,
                                    snrInSet))
}
pseudo <- data.table::rbindlist(pseudo)
pseudo$V1 <- rev(pseudo$V1) # reverse block assignment  so that words in each set do not appear together with the corresponding pseudo words from that set (avoid phonol bias)
colnames(pseudo) <- c('block','item','snr')
 
# bring together, shuffle
ds <- rbind(words,pseudo)
ds <- ds[sample(1:nrow(ds)),] 
ds <- ds[order(block),]

# fill the file names based on multiple matching/replacements 
ds$file <- paste0(ds$snr,'.mp3')
ds$file <- ifelse(ds$block=='block1' | ds$block=='block3',
                 stringi::stri_replace_all_regex(ds$file,pattern = snrLev,replacement = paste0('norm_',snrs_voco),vectorize = FALSE),
                 stringi::stri_replace_all_regex(ds$file,pattern = snrLev,replacement = paste0('norm',snrs_sissn),vectorize = FALSE))

ds$file <- ifelse(ds$block=='block1' | ds$block=='block3',
                paste('NV',ds$item,ds$file,sep='_'),
                paste('SiSSN',ds$item,ds$file,sep='_'))

ds$type <- ifelse(ds$block=='block1' | ds$block=='block3','NV','SiSSN') 
print(ds)
# save in output dir 
dirout <-  paste0(diroutput,'/LexicalDecision/')
outputname <- paste0(dirout,'TrialSequences_LD.xlsx')
openxlsx::write.xlsx(ds,outputname)

# save only if not previously saved
if (!dir.exists(paste0(dirout,'/files'))){
    dir.create(paste0(dirout,'/files'))
    file.copy(paste0(audiofiles_sissn,filessissn[which(filessissn %in% ds$file)]),paste0(dirout,'/files'))
    file.copy(paste0(audiofiles_nvoc,filesnvoc[which(filesnvoc %in% ds$file)]),paste0(dirout,'/files'))
}
rm(ds)

 
###############
# Picture matching task ----------------------------------------------------------
setwd(dirinput100)
ds <- list()
for (i in 1:4){
  currSet <-read.table(paste0('list2match100_set',i,'.txt'))
  
  if (nrow(currSet) %% length(snrLev)!=0){
    stop("not possible to balance n trials per snr ! ")
  }
  # first add all pictures 
  picture <- database$PICTURE[which(database$CORRECT_SPELL %in% currSet$V1 )]
  name <- database$CORRECT_SPELL[which(database$CORRECT_SPELL %in% currSet$V1 )]
  # Add whether they are match or not (50% match)
  match <- c(rep(1,nrow(currSet)/2),rep(0,nrow(currSet)/2)) %>% sample()
  
  #Combine 
  spreadsheet  <- as.data.frame(cbind(rep(paste0('block',i),nrow(currSet)), 
                                      name,
                                      rep(snrLev,nrow(currSet)/length(snrLev)),
                                      picture,
                                      match))
               
  # shuffle the pictures for the trials marked as not a match
  original  <- spreadsheet$picture[which(spreadsheet$match==0)]
  replacement <- sample(original)
    while (length(which(original==replacement)>0)!=0) {# shuffle again until no name repeats position 
    replacement <- sample(original)
  } 
  
  spreadsheet <- spreadsheet[sample(nrow(spreadsheet)),]
  # Add to list 
  ds[[i]] <- spreadsheet
}
# Gather
ds <- data.table::rbindlist(ds)
colnames(ds) <- c('block','item','snr','pic','match') 
 
# fill the file names based on multiple matching/replacements 
ds$file <- paste0(ds$snr,'.mp3')
ds$file <- ifelse(ds$block=='block1' | ds$block=='block3',
                  stringi::stri_replace_all_regex(ds$file,pattern = snrLev,replacement = paste0('norm_',snrs_voco),vectorize = FALSE),
                  stringi::stri_replace_all_regex(ds$file,pattern = snrLev,replacement = paste0('norm',snrs_sissn),vectorize = FALSE))

ds$file <- ifelse(ds$block=='block1' | ds$block=='block3',
                  paste('NV',ds$item,ds$file,sep='_'),
                  paste('SiSSN',ds$item,ds$file,sep='_'))

ds$type <- ifelse(ds$block=='block1' | ds$block=='block3','NV','SiSSN') 

 
# save in output dir 
dirout <-  paste0(diroutput,'/PictureMatching/')
outputname <- paste0(dirout,'TrialSequences_PIC.xlsx')
 
# save in output dir 
openxlsx::write.xlsx(ds,outputname) 
if (!dir.exists(paste0(dirout,'/files'))){
  dir.create(paste0(dirout,'/files'))
  file.copy(paste0(audiofiles_sissn,filessissn[which(filessissn %in% ds$file)]),paste0(dirout,'/files')) 
  file.copy(paste0(audiofiles_nvoc,filesnvoc[which(filesnvoc %in% ds$file)]),paste0(dirout,'/files'))  
}
rm(ds)
# 
# 
# # 4FC ----------------------------------------------------------
# words <- list()
# for (i in 1:4){
#   currSet <-read.table(paste0('list2match100_set',i,'.txt'))
#   if (nrow(currSet) %% length(snrLev)!=0){
#     stop("not possible to balance n trials per snr ! ")
#   }
#   #find words and matching pseudowords
#   wordsInSet <-database$CORRECT_SPELL[which(database$CORRECT_SPELL %in% currSet$V1)]
#   pseudoInSet <-database$Pseudoword[which(database$CORRECT_SPELL %in% currSet$V1)] %>% 
#     gsub('-','',.)
#   nSylablesInSet <-database$nSyllables[which(database$CORRECT_SPELL %in% currSet$V1)]
#   half <- rep(c(1,2),each=length(wordsInSet)/2)
#   
#   tbl <- as.data.frame(cbind(half,wordsInSet,pseudoInSet,nSylablesInSet))
#   tbl1 <- tbl[which(tbl$half==1),]
#   tbl2 <- tbl[which(tbl$half==2),]
#   
#   counter <- 0 
#   while (length(which(abs(as.numeric(tbl1$nSylablesInSet)-as.numeric(tbl2$nSylablesInSet))>1))>0){
#     tbl2 <-   tbl2[sample(1:nrow(tbl2)),]
#     counter <- counter + 1 
#     print(counter)
#     
#   }              
#   
#   block <- rep(paste0('block',i),length(wordsInSet))
#   
#   #words[[i]] <-as.data.frame(cbind(block,half,item))
# }
# #words <- data.table::rbindlist(words)
# 
# #
# pseudo <- list()
# for (i in 1:5){
#   currSet <-read.table(paste0('list2match_set',i,'.txt'))
#   if (nrow(currSet) %% length(snrLev)!=0){
#     stop("not possible to balance n trials per snr ! ")
#   }
#   #find matching pseudowords  # shuffle and add snr 
#   pseudoInSet <-database$Pseudoword[which(database$CORRECT_SPELL %in% currSet$V1)]
#   pseudoInSet <- pseudoInSet %>% sample %>% paste0(.,'_',snrLev)
#   block <- rep(paste0('block',i),length(pseudoInSet))
#   item <- pseudoInSet
#   half <- rep(c(1,2),each=length(pseudoInSet)/2)
#   pseudo[[i]] <- as.data.frame(cbind(block,half,item))
# }
# pseudo <- data.table::rbindlist(pseudo)
# 
# 
# 
# 
# # ds <- list()
# # for (i in 1:5){
# #   currSet <-read.table(paste0('list2match_set',i,'.txt'))
# #   
# #   if (nrow(currSet) %% length(snrLev)!=0){
# #     stop("not possible to balance n trials per snr ! ")
# #   }
# #   
# #   
# #   wordsInSet <- database$CORRECT_SPELL[which(database$CORRECT_SPELL %in% currSet$V1)]
# #   ##  find pseudowords, split in two (shuffle first )
# #   pseudoInSet <- database$Pseudoword[which( database$CORRECT_SPELL %in% currSet$V1)]
# #   pseudoInSet <- gsub('-','',pseudoInSet) 
# #     
# #   half1 <- cbind(wordsInSet[1:(length(wordsInSet)/2)],
# #                    pseudoInSet[1:(length(pseudoInSet)/2)])
# #                    
# #   half2 <- cbind(wordsInSet[(1+length(wordsInSet)/2):length(wordsInSet)],
# #                    pseudoInSet[(1+length(pseudoInSet)/2):length(pseudoInSet)])
# #   
# #   
# #     #  put in table 
# #     spreadsheet <- as.data.frame(cbind(half1,half2))
# #     
# #     # select targets (half words, half pseudowords) 
# #     targets <- spreadsheet$V1
# #     targets[1:(nrow(spreadsheet)/2)] <- spreadsheet$V2[1:(nrow(spreadsheet)/2)]
# #     targets <- paste0(targets,'_',snrLev);
# #     
# #     #shuffle the columns for positions per row, keep targets locked ,add target as first column
# #     spreadsheet <- cbind(targets,as.data.frame(t(apply(spreadsheet,FUN=sample,1))))
# #     spreadsheet <- cbind(rep(paste0('set',i),nrow(spreadsheet)), spreadsheet)
# #     colnames(spreadsheet)<-c('set','target','up','right','down','left')
# #     ds[[i]] <-spreadsheet
# # }
# # 
# # ds <- data.table::rbindlist(ds)
# 
# # save in output dir 
# openxlsx::write.xlsx(ds,paste0(diroutput,'/4ForcedChoice/TrialSequences_4FC.xlsx'))
# rm(ds)
# rm(spreadsheet)
